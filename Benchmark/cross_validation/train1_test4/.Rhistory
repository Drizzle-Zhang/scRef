for (sub.time in names(df.GSEA.male)) {
df.heatmap.male <-
rbind(df.heatmap.male,
data.frame(pathway = pathway, time = sub.time,
score = df.GSEA.male[pathway, sub.time],
stringsAsFactors = F))
}
}
df.heatmap.male$pathway <-
factor(df.heatmap.male$pathway,
levels = as.character(df.ks.male.filter$pathway), ordered = T)
plot.heatmap.male <-
ggplot(data = df.heatmap.male,
aes(x = time, y = pathway, fill = score)) +
geom_tile() +
scale_fill_gradient2(low = muted("blue"), high = muted("red")) +
labs(x = 'Time', y = 'Pathway', fill = 'Enrichment Score') +
theme(panel.background = element_rect(color = 'white', size = 1.5,
fill = 'transparent'),
axis.ticks = element_blank(),
axis.text.x = element_text(size = 9),
legend.text = element_text(size = 12))
ggsave(filename = paste0("/Combine_Heatmap_GSEA_",
paste0(as.character(vec.dose), collapse = ''), ".png"),
path = path.plot, plot = plot.heatmap.male,
height = 12, width = 20, units = 'cm')
library(scales)
plot.heatmap.male <-
ggplot(data = df.heatmap.male,
aes(x = time, y = pathway, fill = score)) +
geom_tile() +
scale_fill_gradient2(low = muted("blue"), high = muted("red")) +
labs(x = 'Time', y = 'Pathway', fill = 'Enrichment Score') +
theme(panel.background = element_rect(color = 'white', size = 1.5,
fill = 'transparent'),
axis.ticks = element_blank(),
axis.text.x = element_text(size = 9),
legend.text = element_text(size = 12))
ggsave(filename = paste0("/Combine_Heatmap_GSEA_",
paste0(as.character(vec.dose), collapse = ''), ".png"),
path = path.plot, plot = plot.heatmap.male,
height = 12, width = 20, units = 'cm')
file.MCA <- '/home/drizzle_zhang/scRef/try_data/MCA_combined_mouse_uniform.txt'
df.MCA <- read.table(file.MCA, header=T, row.names=1, sep='\t', check.name=F)
=
=
errorCondition('123')
fpm.MCA <- fpm(obj.DESeq.MCA, robust = T)
setwd('/home/drizzle_zhang/my_git/scRef/Benchmark/cross_validation/train4_test1')
source('./Cross_Validation.R')
source('./method_functions.R')
source('./evaluate.R')
path.input <- '/home/drizzle_zhang/scRef/'
path.output <- '/home/drizzle_zhang/scRef/cross_validation/train4_test1/'
# generate cross validation dataset
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
OutputDir <- path.output
# Cross_Validation(LabelsPath, OutputDir)
DataPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat.txt')
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
CV_RDataPath <- paste0(path.output, 'CV_folds.RData')
# singleCellNet
run_singleCellNet(DataPath,LabelsPath,CV_RDataPath,OutputDir)
TrueLabelsPath <- paste0(OutputDir, 'singleCellNet_True_Labels.csv')
PredLabelsPath <- paste0(OutputDir, 'singleCellNet_Pred_Labels.csv')
res.singleCellNet <- evaluate(TrueLabelsPath, PredLabelsPath)
TrueLabelsPath <- paste0(OutputDir, 'singleCellNet_True_Labels.csv')
PredLabelsPath <- paste0(OutputDir, 'singleCellNet_Pred_Labels.csv')
res.singleCellNet <- evaluate(TrueLabelsPath, PredLabelsPath)
res.singleCellNet$Mean_F1
res.singleCellNet$PercUnl
TrueLabelsPath <- paste0(OutputDir, 'scRef_True_Labels.csv')
PredLabelsPath <- paste0(OutputDir, 'scRef_Pred_Labels_cell.csv')
# PredLabelsPath <- paste0(OutputDir, 'scRef_Pred_Labels.csv')
res.scRef <- evaluate(TrueLabelsPath, PredLabelsPath)
res.scRef$Mean_F1
# CaSTLe
run_CaSTLe(DataPath,LabelsPath,CV_RDataPath,OutputDir)
Data <- read.csv(DataPath,row.names = 1)
Labels <- as.matrix(read.csv(LabelsPath))
load(CV_RDataPath)
Labels <- as.vector(Labels[,col_Index])
Data <- Data[Cells_to_Keep,]
Labels <- Labels[Cells_to_Keep]
library(igraph)
library(xgboost)
True_Labels_Castle <- list()
Pred_Labels_Castle <- list()
Training_Time_Castle <- list()
Testing_Time_Castle <- list()
BREAKS=c(-1, 0, 1, 6, Inf)
nFeatures = 100
i=1
ds1 = Data[Train_Idx[[i]],]
ds2 = Data[Test_Idx[[i]],]
sourceCellTypes = as.factor(Labels[Train_Idx[[i]]])
targetCellTypes = as.factor(Labels[Test_Idx[[i]]])
start_time <- Sys.time()
# 2. Unify sets, excluding low expressed genes
source_n_cells_counts = apply(ds1, 2, function(x) { sum(x > 0) } )
target_n_cells_counts = apply(ds2, 2, function(x) { sum(x > 0) } )
common_genes = intersect( colnames(ds1)[source_n_cells_counts>10],
colnames(ds2)[target_n_cells_counts>10])
remove(source_n_cells_counts, target_n_cells_counts)
ds1 = ds1[, colnames(ds1) %in% common_genes]
ds2 = ds2[, colnames(ds2) %in% common_genes]
ds = rbind(ds1[,common_genes], ds2[,common_genes])
isSource = c(rep(TRUE,nrow(ds1)), rep(FALSE,nrow(ds2)))
remove(ds1, ds2)
# 3. Highest mean in both source and target
topFeaturesAvg = colnames(ds)[order(apply(ds, 2, mean), decreasing = T)]
end_time <- Sys.time()
Training_Time_Castle[i] <- as.numeric(difftime(end_time,start_time,units = 'secs'))
start_time <- Sys.time()
# for each cell - what is the most probable classification?
L = length(levels(sourceCellTypes))
targetClassification = as.data.frame(matrix(rep(0,L*sum(!isSource)), nrow=L), row.names = levels(sourceCellTypes))
for (cellType in levels(sourceCellTypes)) {
inSourceCellType = as.factor(ifelse(sourceCellTypes == cellType, cellType, paste0("NOT",cellType)))
# 4. Highest mutual information in source
topFeaturesMi = names(sort(apply(ds[isSource,],2,function(x) { compare(cut(x,breaks=BREAKS),inSourceCellType,method = "nmi") }), decreasing = T))
# 5. Top n genes that appear in both mi and avg
selectedFeatures = union(head(topFeaturesAvg, nFeatures) , head(topFeaturesMi, nFeatures) )
# 6. remove correlated features
tmp = cor(ds[,selectedFeatures], method = "pearson")
tmp[!lower.tri(tmp)] = 0
selectedFeatures = selectedFeatures[apply(tmp,2,function(x) any(x < 0.9))]
remove(tmp)
# 7,8. Convert data from continous to binned dummy vars
# break datasets to bins
dsBins = apply(ds[, selectedFeatures], 2, cut, breaks= BREAKS)
# use only bins with more than one value
nUniq = apply(dsBins, 2, function(x) { length(unique(x)) })
# convert to dummy vars
ds0 = model.matrix(~ . , as.data.frame(dsBins[,nUniq>1]))
remove(dsBins, nUniq)
cat(paste0("<h2>Classifier for ",cellType,"</h2>"))
inTypeSource = sourceCellTypes == cellType
# 9. Classify
xg=xgboost(data=ds0[isSource,] ,
label=inTypeSource,
objective="binary:logistic",
eta=0.7 , nthread=1, nround=20, verbose=0,
gamma=0.001, max_depth=5, min_child_weight=10)
# 10. Predict
inTypeProb = predict(xg, ds0[!isSource, ])
targetClassification[cellType,] = inTypeProb
}
cellType=levels(sourceCellTypes)[1]
cellType
inSourceCellType = as.factor(ifelse(sourceCellTypes == cellType, cellType, paste0("NOT",cellType)))
# 4. Highest mutual information in source
topFeaturesMi = names(sort(apply(ds[isSource,],2,function(x) { compare(cut(x,breaks=BREAKS),inSourceCellType,method = "nmi") }), decreasing = T))
# 5. Top n genes that appear in both mi and avg
selectedFeatures = union(head(topFeaturesAvg, nFeatures) , head(topFeaturesMi, nFeatures) )
# 6. remove correlated features
tmp = cor(ds[,selectedFeatures], method = "pearson")
tmp[!lower.tri(tmp)] = 0
selectedFeatures = selectedFeatures[apply(tmp,2,function(x) any(x < 0.9))]
remove(tmp)
# 7,8. Convert data from continous to binned dummy vars
# break datasets to bins
dsBins = apply(ds[, selectedFeatures], 2, cut, breaks= BREAKS)
# use only bins with more than one value
nUniq = apply(dsBins, 2, function(x) { length(unique(x)) })
# convert to dummy vars
ds0 = model.matrix(~ . , as.data.frame(dsBins[,nUniq>1]))
remove(dsBins, nUniq)
cat(paste0("<h2>Classifier for ",cellType,"</h2>"))
inTypeSource = sourceCellTypes == cellType
inSourceCellType = as.factor(ifelse(sourceCellTypes == cellType, cellType, paste0("NOT",cellType)))
inSourceCellType
# 4. Highest mutual information in source
topFeaturesMi = names(sort(apply(ds[isSource,],2,function(x) { compare(cut(x,breaks=BREAKS),inSourceCellType,method = "nmi") }), decreasing = T))
BREAKS
BREAKS
head(ds[isSource,])
ds1 = Data[Train_Idx[[i]],]
ds2 = Data[Test_Idx[[i]],]
setwd('/home/drizzle_zhang/my_git/scRef/Benchmark/cross_validation/train4_test1')
source('./Cross_Validation.R')
source('./method_functions.R')
source('./evaluate.R')
# CaSTLe
run_CaSTLe(DataPath,LabelsPath,CV_RDataPath,OutputDir)
TrueLabelsPath <- paste0(OutputDir, 'CaSTLe_True_Labels.csv')
PredLabelsPath <- paste0(OutputDir, 'CaSTLe_Pred_Labels.csv')
res.CaSTLe <- evaluate(TrueLabelsPath, PredLabelsPath)
TrueLabelsPath <- paste0(OutputDir, 'CaSTLe_True_Labels.csv')
PredLabelsPath <- paste0(OutputDir, 'CaSTLe_Pred_Labels.csv')
res.CaSTLe <- evaluate(TrueLabelsPath, PredLabelsPath)
# CaSTLe
run_CaSTLe(DataPath,LabelsPath,CV_RDataPath,OutputDir)
setwd('/home/drizzle_zhang/my_git/scRef/Benchmark/cross_validation/train4_test1')
source('./Cross_Validation.R')
source('./method_functions.R')
source('./evaluate.R')
path.input <- '/home/drizzle_zhang/scRef/'
path.output <- '/home/drizzle_zhang/scRef/cross_validation/train4_test1/'
# generate cross validation dataset
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
OutputDir <- path.output
# Cross_Validation(LabelsPath, OutputDir)
DataPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat.txt')
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
CV_RDataPath <- paste0(path.output, 'CV_folds.RData')
# scID
run_scID(DataPath,LabelsPath,CV_RDataPath,OutputDir)
# CaSTLe
run_CaSTLe(DataPath,LabelsPath,CV_RDataPath,OutputDir)
TrueLabelsPath <- paste0(OutputDir, 'CaSTLe_True_Labels.csv')
PredLabelsPath <- paste0(OutputDir, 'CaSTLe_Pred_Labels.csv')
res.CaSTLe <- evaluate(TrueLabelsPath, PredLabelsPath)
res.CaSTLe$Mean_F1
res.CaSTLe$F1
res.CaSTLe$PercUnl
TrueLabelsPath <- paste0(OutputDir, 'CaSTLe_True_Labels.csv')
PredLabelsPath <- paste0(OutputDir, 'CaSTLe_Pred_Labels.csv')
res.CaSTLe <- evaluate(TrueLabelsPath, PredLabelsPath)
res.CaSTLe
true_lab <- unlist(read.csv(TrueLabelsPath, stringsAsFactors = F))
pred_lab <- unlist(read.csv(PredLabelsPath, stringsAsFactors = F))
unique_true <- unlist(unique(true_lab))
unique_true
conf <- table(true_lab,pred_lab)
pop_size <- rowSums(conf)
pred_lab = gsub('Node..','Node',pred_lab)
conf_F1 <- table(true_lab,pred_lab)#,exclude = c('unassigned','Unassigned','Unknown','rand','Node','ambiguous'))
conf_F1
a <- cbind(true_lab, pred_lab)
View(a)
PredLabelsPath
setwd('/home/drizzle_zhang/my_git/scRef/Benchmark/cross_validation/train4_test1')
source('./Cross_Validation.R')
source('./method_functions.R')
source('./evaluate.R')
path.input <- '/home/drizzle_zhang/scRef/'
path.output <- '/home/drizzle_zhang/scRef/cross_validation/train4_test1/'
# generate cross validation dataset
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
OutputDir <- path.output
# Cross_Validation(LabelsPath, OutputDir)
DataPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat.txt')
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
CV_RDataPath <- paste0(path.output, 'CV_folds.RData')
Data <- read.delim(DataPath,row.names = 1)
Labels <- as.matrix(read.delim(LabelsPath, row.names = 1))
load(CV_RDataPath)
Labels <- as.vector(Labels[,col_Index])
Data <- Data[Cells_to_Keep,]
Labels <- Labels[Cells_to_Keep]
library(igraph)
library(xgboost)
True_Labels_Castle <- list()
Pred_Labels_Castle <- list()
Training_Time_Castle <- list()
Testing_Time_Castle <- list()
BREAKS=c(-1, 0, 1, 6, Inf)
nFeatures = 100
i
i
ds1 = Data[Train_Idx[[i]],]
ds2 = Data[Test_Idx[[i]],]
sourceCellTypes = as.factor(Labels[Train_Idx[[i]]])
targetCellTypes = as.factor(Labels[Test_Idx[[i]]])
start_time <- Sys.time()
# 2. Unify sets, excluding low expressed genes
source_n_cells_counts = apply(ds1, 2, function(x) { sum(x > 0) } )
target_n_cells_counts = apply(ds2, 2, function(x) { sum(x > 0) } )
common_genes = intersect( colnames(ds1)[source_n_cells_counts>10],
colnames(ds2)[target_n_cells_counts>10])
remove(source_n_cells_counts, target_n_cells_counts)
ds1 = ds1[, colnames(ds1) %in% common_genes]
ds2 = ds2[, colnames(ds2) %in% common_genes]
ds = rbind(ds1[,common_genes], ds2[,common_genes])
isSource = c(rep(TRUE,nrow(ds1)), rep(FALSE,nrow(ds2)))
remove(ds1, ds2)
# 3. Highest mean in both source and target
topFeaturesAvg = colnames(ds)[order(apply(ds, 2, mean), decreasing = T)]
end_time <- Sys.time()
Training_Time_Castle[i] <- as.numeric(difftime(end_time,start_time,units = 'secs'))
start_time <- Sys.time()
# for each cell - what is the most probable classification?
L = length(levels(sourceCellTypes))
targetClassification = as.data.frame(matrix(rep(0,L*sum(!isSource)), nrow=L), row.names = levels(sourceCellTypes))
cellType=levels(sourceCellTypes)[1]
cellType
inSourceCellType = as.factor(ifelse(sourceCellTypes == cellType, cellType, paste0("NOT",cellType)))
# 4. Highest mutual information in source
topFeaturesMi = names(sort(apply(ds[isSource,],2,function(x) { compare(cut(x,breaks=BREAKS),inSourceCellType,method = "nmi") }), decreasing = T))
# 5. Top n genes that appear in both mi and avg
selectedFeatures = union(head(topFeaturesAvg, nFeatures) , head(topFeaturesMi, nFeatures) )
# 6. remove correlated features
tmp = cor(ds[,selectedFeatures], method = "pearson")
tmp[!lower.tri(tmp)] = 0
selectedFeatures = selectedFeatures[apply(tmp,2,function(x) any(x < 0.9))]
remove(tmp)
# 7,8. Convert data from continous to binned dummy vars
# break datasets to bins
dsBins = apply(ds[, selectedFeatures], 2, cut, breaks= BREAKS)
# use only bins with more than one value
nUniq = apply(dsBins, 2, function(x) { length(unique(x)) })
# convert to dummy vars
ds0 = model.matrix(~ . , as.data.frame(dsBins[,nUniq>1]))
remove(dsBins, nUniq)
cat(paste0("<h2>Classifier for ",cellType,"</h2>"))
inTypeSource = sourceCellTypes == cellType
# 9. Classify
xg=xgboost(data=ds0[isSource,] ,
label=inTypeSource,
objective="binary:logistic",
eta=0.7 , nthread=1, nround=20, verbose=0,
gamma=0.001, max_depth=5, min_child_weight=10)
# 10. Predict
inTypeProb = predict(xg, ds0[!isSource, ])
View(inTypeProb)
for (cellType in levels(sourceCellTypes)) {
inSourceCellType = as.factor(ifelse(sourceCellTypes == cellType, cellType, paste0("NOT",cellType)))
# 4. Highest mutual information in source
topFeaturesMi = names(sort(apply(ds[isSource,],2,function(x) { compare(cut(x,breaks=BREAKS),inSourceCellType,method = "nmi") }), decreasing = T))
# 5. Top n genes that appear in both mi and avg
selectedFeatures = union(head(topFeaturesAvg, nFeatures) , head(topFeaturesMi, nFeatures) )
# 6. remove correlated features
tmp = cor(ds[,selectedFeatures], method = "pearson")
tmp[!lower.tri(tmp)] = 0
selectedFeatures = selectedFeatures[apply(tmp,2,function(x) any(x < 0.9))]
remove(tmp)
# 7,8. Convert data from continous to binned dummy vars
# break datasets to bins
dsBins = apply(ds[, selectedFeatures], 2, cut, breaks= BREAKS)
# use only bins with more than one value
nUniq = apply(dsBins, 2, function(x) { length(unique(x)) })
# convert to dummy vars
ds0 = model.matrix(~ . , as.data.frame(dsBins[,nUniq>1]))
remove(dsBins, nUniq)
cat(paste0("<h2>Classifier for ",cellType,"</h2>"))
inTypeSource = sourceCellTypes == cellType
# 9. Classify
xg=xgboost(data=ds0[isSource,] ,
label=inTypeSource,
objective="binary:logistic",
eta=0.7 , nthread=1, nround=20, verbose=0,
gamma=0.001, max_depth=5, min_child_weight=10)
# 10. Predict
inTypeProb = predict(xg, ds0[!isSource, ])
targetClassification[cellType,] = inTypeProb
}
View(targetClassification)
a=Labels[Test_Idx[[i]]]
b=rownames(targetClassification)[apply(targetClassification,2,which.max)]
View(a)
View(b)
Data <- t(as.matrix(Data))
BREAKS=c(-1, 0, 1, 6, Inf)
nFeatures = 100
for(i in c(1:n_folds)){
# 1. Load datasets
if(!is.null(GeneOrderPath) & !is.null (NumGenes)){
ds1 = Data[Train_Idx[[i]],as.vector(GenesOrder[c(1:NumGenes),i])+1]
ds2 = Data[Test_Idx[[i]],as.vector(GenesOrder[c(1:NumGenes),i])+1]
}
else{
ds1 = Data[Train_Idx[[i]],]
ds2 = Data[Test_Idx[[i]],]
}
sourceCellTypes = as.factor(Labels[Train_Idx[[i]]])
targetCellTypes = as.factor(Labels[Test_Idx[[i]]])
start_time <- Sys.time()
# 2. Unify sets, excluding low expressed genes
source_n_cells_counts = apply(ds1, 2, function(x) { sum(x > 0) } )
target_n_cells_counts = apply(ds2, 2, function(x) { sum(x > 0) } )
common_genes = intersect( colnames(ds1)[source_n_cells_counts>10],
colnames(ds2)[target_n_cells_counts>10])
remove(source_n_cells_counts, target_n_cells_counts)
ds1 = ds1[, colnames(ds1) %in% common_genes]
ds2 = ds2[, colnames(ds2) %in% common_genes]
ds = rbind(ds1[,common_genes], ds2[,common_genes])
isSource = c(rep(TRUE,nrow(ds1)), rep(FALSE,nrow(ds2)))
remove(ds1, ds2)
# 3. Highest mean in both source and target
topFeaturesAvg = colnames(ds)[order(apply(ds, 2, mean), decreasing = T)]
end_time <- Sys.time()
Training_Time_Castle[i] <- as.numeric(difftime(end_time,start_time,units = 'secs'))
start_time <- Sys.time()
# for each cell - what is the most probable classification?
L = length(levels(sourceCellTypes))
targetClassification = as.data.frame(matrix(rep(0,L*sum(!isSource)), nrow=L), row.names = levels(sourceCellTypes))
for (cellType in levels(sourceCellTypes)) {
inSourceCellType = as.factor(ifelse(sourceCellTypes == cellType, cellType, paste0("NOT",cellType)))
# 4. Highest mutual information in source
topFeaturesMi = names(sort(apply(ds[isSource,],2,function(x) { compare(cut(x,breaks=BREAKS),inSourceCellType,method = "nmi") }), decreasing = T))
# 5. Top n genes that appear in both mi and avg
selectedFeatures = union(head(topFeaturesAvg, nFeatures) , head(topFeaturesMi, nFeatures) )
# 6. remove correlated features
tmp = cor(ds[,selectedFeatures], method = "pearson")
tmp[!lower.tri(tmp)] = 0
selectedFeatures = selectedFeatures[apply(tmp,2,function(x) any(x < 0.9))]
remove(tmp)
# 7,8. Convert data from continous to binned dummy vars
# break datasets to bins
dsBins = apply(ds[, selectedFeatures], 2, cut, breaks= BREAKS)
# use only bins with more than one value
nUniq = apply(dsBins, 2, function(x) { length(unique(x)) })
# convert to dummy vars
ds0 = model.matrix(~ . , as.data.frame(dsBins[,nUniq>1]))
remove(dsBins, nUniq)
cat(paste0("<h2>Classifier for ",cellType,"</h2>"))
inTypeSource = sourceCellTypes == cellType
# 9. Classify
xg=xgboost(data=ds0[isSource,] ,
label=inTypeSource,
objective="binary:logistic",
eta=0.7 , nthread=1, nround=20, verbose=0,
gamma=0.001, max_depth=5, min_child_weight=10)
# 10. Predict
inTypeProb = predict(xg, ds0[!isSource, ])
targetClassification[cellType,] = inTypeProb
}
end_time <- Sys.time()
Testing_Time_Castle[i] <- as.numeric(difftime(end_time,start_time,units = 'secs'))
True_Labels_Castle[i] <- list(Labels[Test_Idx[[i]]])
Pred_Labels_Castle[i] <- list(rownames(targetClassification)[apply(targetClassification,2,which.max)])
}
True_Labels_Castle <- as.vector(unlist(True_Labels_Castle))
Pred_Labels_Castle <- as.vector(unlist(Pred_Labels_Castle))
Training_Time_Castle <- as.vector(unlist(Training_Time_Castle))
Testing_Time_Castle <- as.vector(unlist(Testing_Time_Castle))
setwd('/home/drizzle_zhang/my_git/scRef/Benchmark/cross_validation/train4_test1')
source('./Cross_Validation.R')
source('./method_functions.R')
source('./evaluate.R')
path.input <- '/home/drizzle_zhang/scRef/'
path.output <- '/home/drizzle_zhang/scRef/cross_validation/train4_test1/'
# generate cross validation dataset
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
OutputDir <- path.output
# Cross_Validation(LabelsPath, OutputDir)
DataPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat.txt')
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
CV_RDataPath <- paste0(path.output, 'CV_folds.RData')
# CaSTLe
run_CaSTLe(DataPath,LabelsPath,CV_RDataPath,OutputDir)
TrueLabelsPath <- paste0(OutputDir, 'CaSTLe_True_Labels.csv')
PredLabelsPath <- paste0(OutputDir, 'CaSTLe_Pred_Labels.csv')
res.CaSTLe <- evaluate(TrueLabelsPath, PredLabelsPath)
res.CaSTLe$Mean_F1
res.scRef$Mean_F1
res.scRef$PercUnl
res.CaSTLe$PercUnl
Data <- read.delim(DataPath,row.names = 1)
Labels <- as.matrix(read.delim(LabelsPath, row.names = 1))
load(CV_RDataPath)
Labels <- as.vector(Labels[,col_Index])
Data <- Data[Cells_to_Keep,]
Labels <- Labels[Cells_to_Keep]
library(scID)
library(Seurat)
True_Labels_scID <- list()
Pred_Labels_scID <- list()
Total_Time_scID <- list()
Data = as.matrix(Data)
i
Train_Labels <- list(Labels[Train_Idx[[i]]])
names(Train_Labels[[1]]) <- colnames(Data[,Train_Idx[[i]]])
scID_output <- scid_multiclass(Data[,Test_Idx[[i]]], Data[,Train_Idx[[i]]], Train_Labels[[1]])
scID_output <- scid_multiclass(Data[,Test_Idx[[i]]], Data[,Train_Idx[[i]]], Train_Labels[[1]])
# scID
run_scID(DataPath,LabelsPath,CV_RDataPath,OutputDir)
setwd('/home/drizzle_zhang/my_git/scRef/Benchmark/cross_validation/train4_test1')
source('./Cross_Validation.R')
source('./method_functions.R')
source('./evaluate.R')
path.input <- '/home/drizzle_zhang/scRef/'
path.output <- '/home/drizzle_zhang/scRef/cross_validation/train4_test1/'
# generate cross validation dataset
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
OutputDir <- path.output
# Cross_Validation(LabelsPath, OutputDir)
DataPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat.txt')
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
CV_RDataPath <- paste0(path.output, 'CV_folds.RData')
# scID
run_scID(DataPath,LabelsPath,CV_RDataPath,OutputDir)
TrueLabelsPath <- paste0(OutputDir, 'scID_True_Labels.csv')
PredLabelsPath <- paste0(OutputDir, 'scID_Pred_Labels.csv')
res.scID <- evaluate(TrueLabelsPath, PredLabelsPath)
res.scID$Mean_F1
res.scID$F1
res.scID$PercUnl
setwd('/home/drizzle_zhang/my_git/scRef/Benchmark/cross_validation/train1_test4')
source('./Cross_Validation.R')
source('./method_functions.R')
source('./evaluate.R')
path.input <- '/home/drizzle_zhang/scRef/'
path.output <- '/home/drizzle_zhang/scRef/cross_validation/train1_test4/'
# generate cross validation dataset
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
OutputDir <- path.output
# Cross_Validation(LabelsPath, OutputDir)
DataPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat.txt')
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
CV_RDataPath <- paste0(path.output, 'CV_folds.RData')
setwd('/home/drizzle_zhang/my_git/scRef/Benchmark/cross_validation/train1_test4')
source('./Cross_Validation.R')
source('./method_functions.R')
source('./evaluate.R')
path.input <- '/home/drizzle_zhang/scRef/'
path.output <- '/home/drizzle_zhang/scRef/cross_validation/train1_test4/'
# generate cross validation dataset
LabelsPath <- paste0(path.input, 'summary/Zeisel_exp_sc_mat_cluster_original.txt')
OutputDir <- path.output
Cross_Validation(LabelsPath, OutputDir)
